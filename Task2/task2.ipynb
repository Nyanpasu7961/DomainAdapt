{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry Chan\\anaconda3\\envs\\mlearn\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_to_label= {\n",
    "    0: \"backpack\",\n",
    "    1: \"book\",\n",
    "    2: \"car\",\n",
    "    3: \"pizza\",\n",
    "    4: \"sandwich\",\n",
    "    5: \"snake\",\n",
    "    6: \"sock\",\n",
    "    7: \"tiger\",\n",
    "    8: \"tree\",\n",
    "    9: \"watermelon\"\n",
    "}\n",
    "\n",
    "label_to_num = dict((v,k) for k,v in num_to_label.items())\n",
    "\n",
    "# Obtains all the labels from a root directory.\n",
    "def obtain_labels(root_dir):\n",
    "    labels = []\n",
    "    # Find all files contained in the root directory\n",
    "    walk = os.walk(root_dir, topdown=False)\n",
    "    for root, _, files in walk:\n",
    "        # Ignore the root directory\n",
    "        if root_dir == root: continue\n",
    "        # Extract the label from the current directory\n",
    "        root = os.path.basename(root)\n",
    "        # Concatenate the labels from the curr. directory.\n",
    "        labels += list(map(lambda x: [x, root], files))\n",
    "\n",
    "    return np.array(labels)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = obtain_labels(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx, 1], self.img_labels[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "class LabelToNum(torch.nn.Module):\n",
    "    def forward(self, label):\n",
    "        return label_to_num[label]\n",
    "\n",
    "label_transform = LabelToNum()\n",
    "\n",
    "dataset_transform = v2.Compose([\n",
    "    v2.Resize(size=(224, 224)),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_valid(dataset, validation_split=0.2, random_seed=42):\n",
    "    # Creating data indices for training and validation splits.\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    # Shuffle the indices based on a random seed.\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    # Split the training and validation indices\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Create the samplers for training and validation.\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    return train_sampler, valid_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain Real datasets and split for validation sets.\n",
    "train_dataset_real = CustomImageDataset(img_dir=\"data/real_train\", transform=dataset_transform, target_transform=label_transform)\n",
    "test_dataset_real = CustomImageDataset(img_dir=\"data/real_test\", transform=dataset_transform, target_transform=label_transform)\n",
    "\n",
    "## Obtain Sketch datasets and split for validation sets.\n",
    "train_dataset_sketch = CustomImageDataset(img_dir=\"data/sketch_train\", transform=dataset_transform, target_transform=label_transform)\n",
    "test_dataset_sketch = CustomImageDataset(img_dir=\"data/sketch_test\", transform=dataset_transform, target_transform=label_transform)\n",
    "\n",
    "t_real_sample, v_real_sample = split_valid(train_dataset_real)\n",
    "t_sketch_sample, v_sketch_sample = split_valid(train_dataset_sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# Training init\n",
    "learning_rate = 1e-3\n",
    "epochs = 25\n",
    "\n",
    "real_size = len(train_dataset_real)\n",
    "sketch_size = len(train_dataset_sketch)\n",
    "batch_ratio = real_size/sketch_size\n",
    "batch_sketch_size = 50\n",
    "batch_size = {'real': int(batch_sketch_size*batch_ratio), 'sketch':batch_sketch_size}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Real domain DataLoaders\n",
    "# DataLoader for Training\n",
    "dl_train_real = DataLoader(train_dataset_real, batch_size=batch_size['real'], sampler=t_real_sample)\n",
    "# DataLoader for Validation\n",
    "dl_valid_real = DataLoader(train_dataset_real, batch_size=batch_size['real'], sampler=v_real_sample)\n",
    "# DataLoader for Testing\n",
    "dl_test_real = DataLoader(test_dataset_real, batch_size=batch_size['real'], shuffle=True)\n",
    "\n",
    "## Sketch domain DataLoaders\n",
    "# DataLoader for Training\n",
    "dl_train_sketch = DataLoader(train_dataset_sketch, batch_size=batch_size['sketch'], sampler=t_sketch_sample)\n",
    "# DataLoader for Validation\n",
    "dl_valid_sketch = DataLoader(train_dataset_sketch, batch_size=batch_size['sketch'], sampler=v_sketch_sample)\n",
    "# DataLoader for Testing\n",
    "dl_test_sketch = DataLoader(test_dataset_sketch, batch_size=batch_size['sketch'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(src_loader, model, loss_fn, optimizer, lr_optimizer, epoch, device):\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "   \n",
    "    for idx, (data, targets) in enumerate(src_loader):\n",
    "        # Map the data and targets to GPU.\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Predict labels using the model\n",
    "        scores = model(data)\n",
    "        # Calculate the cross-entropy loss\n",
    "        loss = loss_fn(scores, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters according to gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather correct predictions done by the model to determine training accuaracy.\n",
    "        _, predictions = scores.max(1)\n",
    "        num_correct += (predictions == targets).sum()\n",
    "        num_samples += predictions.size(0)\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        \n",
    "        # report every 100 iterations\n",
    "        if idx % 25 == 24:\n",
    "            print(' epoch {} loss: {:.4f}'.format(epoch+1, running_loss / 25))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    \n",
    "    print(optimizer.param_groups[0][\"lr\"])\n",
    "    lr_optimizer.step()\n",
    "\n",
    "    train_loss = train_loss/(idx+1)\n",
    "    train_acc = num_correct/num_samples\n",
    "\n",
    "    print(f'Epoch [{epoch+1}], '\n",
    "          f'Train Loss: {train_loss:.4f}, ')\n",
    "    print(f'{num_correct}/{num_samples} train accuracy {num_correct/num_samples}')\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test(src_loader, model, loss_fn, device):\n",
    "\n",
    "    valid_loss = 0\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in src_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            scores = model(data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "            valid_loss += loss_fn(scores, targets)\n",
    "        \n",
    "        print(f'{num_correct}/{num_samples} accuracy {num_correct/num_samples}')\n",
    "\n",
    "    # Gather data and report\n",
    "    valid_loss /= len(src_loader)\n",
    "    accuracy = num_correct/num_samples\n",
    "    print(\"Test Error: \\n   Accuracy: {:.2f}, Avg loss: {:.4f} \\n\".format(100*accuracy, valid_loss))\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ResNet-34 model on the Sketch domain and evaluations on the Sketch domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn34_model = models.resnet34(weights='DEFAULT')\n",
    "num_ftrs = rn34_model.fc.in_features\n",
    "rn34_model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Freeze all gradients on parameters.\n",
    "for p in rn34_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Thaw gradients for layer 4.\n",
    "for p in rn34_model.layer4.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 1 loss: 0.9715\n",
      "0.001\n",
      "Epoch [1], Train Loss: 0.9579, \n",
      "1085/1565 train accuracy 0.6932907104492188\n",
      "304/391 accuracy 0.7774935960769653\n",
      "Test Error: \n",
      "   Accuracy: 77.75, Avg loss: 1.1574 \n",
      "\n",
      "Epoch: 1 Train_loss: 0.9579096520319581 Valid_loss: 1.1574413776397705 Valid_acc: 0.7774935960769653\n",
      " epoch 2 loss: 0.5170\n",
      "0.0009949107209404665\n",
      "Epoch [2], Train Loss: 0.5427, \n",
      "1316/1565 train accuracy 0.8408945798873901\n",
      "322/391 accuracy 0.8235294222831726\n",
      "Test Error: \n",
      "   Accuracy: 82.35, Avg loss: 0.6617 \n",
      "\n",
      "Epoch: 2 Train_loss: 0.5427498538047075 Valid_loss: 0.6616586446762085 Valid_acc: 0.8235294222831726\n",
      " epoch 3 loss: 0.3743\n",
      "0.000979746486807249\n",
      "Epoch [3], Train Loss: 0.3915, \n",
      "1371/1565 train accuracy 0.8760383129119873\n",
      "326/391 accuracy 0.833759605884552\n",
      "Test Error: \n",
      "   Accuracy: 83.38, Avg loss: 0.5681 \n",
      "\n",
      "Epoch: 3 Train_loss: 0.39153885561972857 Valid_loss: 0.5680795311927795 Valid_acc: 0.833759605884552\n",
      " epoch 4 loss: 0.2946\n",
      "0.0009548159976772593\n",
      "Epoch [4], Train Loss: 0.2928, \n",
      "1411/1565 train accuracy 0.9015974402427673\n",
      "307/391 accuracy 0.7851662635803223\n",
      "Test Error: \n",
      "   Accuracy: 78.52, Avg loss: 0.7540 \n",
      "\n",
      "Epoch: 4 Train_loss: 0.2927524568513036 Valid_loss: 0.7540251016616821 Valid_acc: 0.7851662635803223\n",
      " epoch 5 loss: 0.2358\n",
      "0.0009206267664155907\n",
      "Epoch [5], Train Loss: 0.2417, \n",
      "1437/1565 train accuracy 0.9182108640670776\n",
      "336/391 accuracy 0.8593350052833557\n",
      "Test Error: \n",
      "   Accuracy: 85.93, Avg loss: 0.4981 \n",
      "\n",
      "Epoch: 5 Train_loss: 0.24167547887191176 Valid_loss: 0.49813899397850037 Valid_acc: 0.8593350052833557\n",
      " epoch 6 loss: 0.1841\n",
      "0.0008778747871771292\n",
      "Epoch [6], Train Loss: 0.1878, \n",
      "1483/1565 train accuracy 0.9476038217544556\n",
      "312/391 accuracy 0.7979539632797241\n",
      "Test Error: \n",
      "   Accuracy: 79.80, Avg loss: 0.6794 \n",
      "\n",
      "Epoch: 6 Train_loss: 0.1878111583646387 Valid_loss: 0.6794137954711914 Valid_acc: 0.7979539632797241\n",
      " epoch 7 loss: 0.1401\n",
      "0.0008274303669726427\n",
      "Epoch [7], Train Loss: 0.1432, \n",
      "1497/1565 train accuracy 0.9565495252609253\n",
      "333/391 accuracy 0.8516623973846436\n",
      "Test Error: \n",
      "   Accuracy: 85.17, Avg loss: 0.5244 \n",
      "\n",
      "Epoch: 7 Train_loss: 0.14321848761755973 Valid_loss: 0.5244256854057312 Valid_acc: 0.8516623973846436\n",
      " epoch 8 loss: 0.0978\n",
      "0.0007703204087277989\n",
      "Epoch [8], Train Loss: 0.1012, \n",
      "1509/1565 train accuracy 0.9642172455787659\n",
      "323/391 accuracy 0.8260869383811951\n",
      "Test Error: \n",
      "   Accuracy: 82.61, Avg loss: 0.6750 \n",
      "\n",
      "Epoch: 8 Train_loss: 0.1012331071542576 Valid_loss: 0.6749955415725708 Valid_acc: 0.8260869383811951\n",
      " epoch 9 loss: 0.0955\n",
      "0.0007077075065009433\n",
      "Epoch [9], Train Loss: 0.1088, \n",
      "1507/1565 train accuracy 0.9629392623901367\n",
      "332/391 accuracy 0.8491048812866211\n",
      "Test Error: \n",
      "   Accuracy: 84.91, Avg loss: 0.6212 \n",
      "\n",
      "Epoch: 9 Train_loss: 0.10877367432112806 Valid_loss: 0.6212392449378967 Valid_acc: 0.8491048812866211\n",
      " epoch 10 loss: 0.1288\n",
      "0.0006408662784207149\n",
      "Epoch [10], Train Loss: 0.1395, \n",
      "1500/1565 train accuracy 0.9584664106369019\n",
      "337/391 accuracy 0.861892580986023\n",
      "Test Error: \n",
      "   Accuracy: 86.19, Avg loss: 0.5816 \n",
      "\n",
      "Epoch: 10 Train_loss: 0.13948088692268357 Valid_loss: 0.5816027522087097 Valid_acc: 0.861892580986023\n",
      " epoch 11 loss: 0.0952\n",
      "0.0005711574191366426\n",
      "Epoch [11], Train Loss: 0.0908, \n",
      "1522/1565 train accuracy 0.9725239276885986\n",
      "328/391 accuracy 0.8388746976852417\n",
      "Test Error: \n",
      "   Accuracy: 83.89, Avg loss: 0.6341 \n",
      "\n",
      "Epoch: 11 Train_loss: 0.09083224547794089 Valid_loss: 0.6340849995613098 Valid_acc: 0.8388746976852417\n",
      " epoch 12 loss: 0.0377\n",
      "0.0005000000000000002\n",
      "Epoch [12], Train Loss: 0.0398, \n",
      "1552/1565 train accuracy 0.9916932582855225\n",
      "339/391 accuracy 0.8670076727867126\n",
      "Test Error: \n",
      "   Accuracy: 86.70, Avg loss: 0.4808 \n",
      "\n",
      "Epoch: 12 Train_loss: 0.03982017969246954 Valid_loss: 0.48076218366622925 Valid_acc: 0.8670076727867126\n",
      " epoch 13 loss: 0.0314\n",
      "0.00042884258086335755\n",
      "Epoch [13], Train Loss: 0.0344, \n",
      "1552/1565 train accuracy 0.9916932582855225\n",
      "333/391 accuracy 0.8516623973846436\n",
      "Test Error: \n",
      "   Accuracy: 85.17, Avg loss: 0.5124 \n",
      "\n",
      "Epoch: 13 Train_loss: 0.03440687307011103 Valid_loss: 0.5123934745788574 Valid_acc: 0.8516623973846436\n",
      " epoch 14 loss: 0.0319\n",
      "0.0003591337215792852\n",
      "Epoch [14], Train Loss: 0.0347, \n",
      "1553/1565 train accuracy 0.9923322796821594\n",
      "332/391 accuracy 0.8491048812866211\n",
      "Test Error: \n",
      "   Accuracy: 84.91, Avg loss: 0.6096 \n",
      "\n",
      "Epoch: 14 Train_loss: 0.03466005159862107 Valid_loss: 0.6096153259277344 Valid_acc: 0.8491048812866211\n",
      " epoch 15 loss: 0.0185\n",
      "0.00029229249349905687\n",
      "Epoch [15], Train Loss: 0.0199, \n",
      "1556/1565 train accuracy 0.994249165058136\n",
      "338/391 accuracy 0.8644500970840454\n",
      "Test Error: \n",
      "   Accuracy: 86.45, Avg loss: 0.4890 \n",
      "\n",
      "Epoch: 15 Train_loss: 0.019855850528983865 Valid_loss: 0.4889696538448334 Valid_acc: 0.8644500970840454\n",
      " epoch 16 loss: 0.0110\n",
      "0.00022967959127220141\n",
      "Epoch [16], Train Loss: 0.0123, \n",
      "1562/1565 train accuracy 0.9980830550193787\n",
      "349/391 accuracy 0.8925831317901611\n",
      "Test Error: \n",
      "   Accuracy: 89.26, Avg loss: 0.4713 \n",
      "\n",
      "Epoch: 16 Train_loss: 0.012328244105447084 Valid_loss: 0.4713499844074249 Valid_acc: 0.8925831317901611\n",
      " epoch 17 loss: 0.0115\n",
      "0.00017256963302735752\n",
      "Epoch [17], Train Loss: 0.0107, \n",
      "1562/1565 train accuracy 0.9980830550193787\n",
      "335/391 accuracy 0.8567774891853333\n",
      "Test Error: \n",
      "   Accuracy: 85.68, Avg loss: 0.5618 \n",
      "\n",
      "Epoch: 17 Train_loss: 0.01066722321411362 Valid_loss: 0.5617645978927612 Valid_acc: 0.8567774891853333\n",
      " epoch 18 loss: 0.0163\n",
      "0.00012212521282287095\n",
      "Epoch [18], Train Loss: 0.0193, \n",
      "1558/1565 train accuracy 0.9955271482467651\n",
      "345/391 accuracy 0.8823529481887817\n",
      "Test Error: \n",
      "   Accuracy: 88.24, Avg loss: 0.5493 \n",
      "\n",
      "Epoch: 18 Train_loss: 0.01929151417061803 Valid_loss: 0.549314022064209 Valid_acc: 0.8823529481887817\n",
      " epoch 19 loss: 0.0108\n",
      "7.937323358440948e-05\n",
      "Epoch [19], Train Loss: 0.0152, \n",
      "1560/1565 train accuracy 0.9968050718307495\n",
      "337/391 accuracy 0.861892580986023\n",
      "Test Error: \n",
      "   Accuracy: 86.19, Avg loss: 0.5600 \n",
      "\n",
      "Epoch: 19 Train_loss: 0.0152452423608338 Valid_loss: 0.56000816822052 Valid_acc: 0.861892580986023\n",
      " epoch 20 loss: 0.0094\n",
      "4.5184002322740903e-05\n",
      "Epoch [20], Train Loss: 0.0116, \n",
      "1561/1565 train accuracy 0.9974440932273865\n",
      "344/391 accuracy 0.8797953724861145\n",
      "Test Error: \n",
      "   Accuracy: 87.98, Avg loss: 0.5596 \n",
      "\n",
      "Epoch: 20 Train_loss: 0.011553071803064086 Valid_loss: 0.5595645904541016 Valid_acc: 0.8797953724861145\n",
      " epoch 21 loss: 0.0192\n",
      "2.0253513192751323e-05\n",
      "Epoch [21], Train Loss: 0.0209, \n",
      "1558/1565 train accuracy 0.9955271482467651\n",
      "337/391 accuracy 0.861892580986023\n",
      "Test Error: \n",
      "   Accuracy: 86.19, Avg loss: 0.5457 \n",
      "\n",
      "Epoch: 21 Train_loss: 0.020870592852588743 Valid_loss: 0.5457046031951904 Valid_acc: 0.861892580986023\n",
      " epoch 22 loss: 0.0078\n",
      "5.08927905953366e-06\n",
      "Epoch [22], Train Loss: 0.0121, \n",
      "1562/1565 train accuracy 0.9980830550193787\n",
      "333/391 accuracy 0.8516623973846436\n",
      "Test Error: \n",
      "   Accuracy: 85.17, Avg loss: 0.5833 \n",
      "\n",
      "Epoch: 22 Train_loss: 0.012087937779142521 Valid_loss: 0.5833376049995422 Valid_acc: 0.8516623973846436\n",
      " epoch 23 loss: 0.0089\n",
      "0.0\n",
      "Epoch [23], Train Loss: 0.0085, \n",
      "1562/1565 train accuracy 0.9980830550193787\n",
      "339/391 accuracy 0.8670076727867126\n",
      "Test Error: \n",
      "   Accuracy: 86.70, Avg loss: 0.6207 \n",
      "\n",
      "Epoch: 23 Train_loss: 0.008548290374164935 Valid_loss: 0.6206727623939514 Valid_acc: 0.8670076727867126\n",
      " epoch 24 loss: 0.0123\n",
      "5.089279059533658e-06\n",
      "Epoch [24], Train Loss: 0.0120, \n",
      "1558/1565 train accuracy 0.9955271482467651\n",
      "336/391 accuracy 0.8593350052833557\n",
      "Test Error: \n",
      "   Accuracy: 85.93, Avg loss: 0.5534 \n",
      "\n",
      "Epoch: 24 Train_loss: 0.012017977525829338 Valid_loss: 0.5533503890037537 Valid_acc: 0.8593350052833557\n",
      " epoch 25 loss: 0.0073\n",
      "2.0253513192751482e-05\n",
      "Epoch [25], Train Loss: 0.0164, \n",
      "1561/1565 train accuracy 0.9974440932273865\n",
      "337/391 accuracy 0.861892580986023\n",
      "Test Error: \n",
      "   Accuracy: 86.19, Avg loss: 0.6505 \n",
      "\n",
      "Epoch: 25 Train_loss: 0.016372828158637276 Valid_loss: 0.6505352258682251 Valid_acc: 0.861892580986023\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "rn34_model.to(device)\n",
    "\n",
    "## Optimizer construction using Adam.\n",
    "params = [p for p in rn34_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params,\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "lr_optimizer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(epochs*0.9))\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# ******************* TensorBoard *******************\n",
    "writer = SummaryWriter(comment=\"SKETCH-ass2\")\n",
    "\n",
    "# ******************* Optimization *******************\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    # set the module in training mode.\n",
    "    rn34_model.train()\n",
    "    train_loss, train_acc = train(dl_train_sketch, rn34_model, loss_fn, optimizer, lr_optimizer, epoch, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "\n",
    "    # save model weights\n",
    "    save_path = 'ckpt_{:04d}.pth'.format(epoch+1)\n",
    "    torch.save(rn34_model.state_dict(), save_path)\n",
    "\n",
    "    # validation loop\n",
    "    # set the module in evaluation mode.\n",
    "    rn34_model.eval()\n",
    "    valid_loss, valid_accuracy = test(dl_valid_sketch, rn34_model, loss_fn, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('valid_loss', valid_loss, epoch)\n",
    "    writer.add_scalar('valid_accuracy', valid_accuracy, epoch)\n",
    "\n",
    "    writer.add_scalars('losses', {'train_loss':train_loss,\n",
    "                                  'valid_loss':valid_loss}, epoch)\n",
    "    \n",
    "    writer.add_scalars('accuracy', {'train_acc':train_acc,\n",
    "                                  'valid_acc':valid_accuracy}, epoch)\n",
    "\n",
    "    if valid_accuracy > best_accuracy:    # save the model with best validation accuracy\n",
    "        save_path = 'ckpt_best.pth'\n",
    "        torch.save(rn34_model.state_dict(), save_path)\n",
    "        best_accuracy = valid_accuracy\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}', f'Train_loss: {train_loss}', f'Valid_loss: {valid_loss}', f'Valid_acc: {valid_accuracy}')\n",
    "\n",
    "writer.close()\n",
    "print(\"Finished Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728/841 accuracy 0.8656361103057861\n",
      "Test Error: \n",
      "   Accuracy: 86.56, Avg loss: 0.5508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rn34_model.to(device)\n",
    "rn34_model.eval()\n",
    "valid_loss, valid_accuracy = test(dl_test_sketch, rn34_model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ResNet-34 model on the Real domain and evaluations on the Sketch domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn34_model = models.resnet34(weights='DEFAULT')\n",
    "num_ftrs = rn34_model.fc.in_features\n",
    "rn34_model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Freeze all gradients on parameters.\n",
    "for p in rn34_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Thaw gradients for layer 4.\n",
    "for p in rn34_model.layer4.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 1 loss: 0.3546\n",
      "0.001\n",
      "Epoch [1], Train Loss: 0.3217, \n",
      "2864/3188 train accuracy 0.8983688950538635\n",
      "185/391 accuracy 0.4731457829475403\n",
      "Test Error: \n",
      "   Accuracy: 47.31, Avg loss: 2.3988 \n",
      "\n",
      "Epoch: 1 Train_loss: 0.3216794291511178 Valid_loss: 2.3987746238708496 Valid_acc: 0.4731457829475403\n",
      " epoch 2 loss: 0.1167\n",
      "0.0009949107209404665\n",
      "Epoch [2], Train Loss: 0.1182, \n",
      "3076/3188 train accuracy 0.9648682475090027\n",
      "178/391 accuracy 0.45524296164512634\n",
      "Test Error: \n",
      "   Accuracy: 45.52, Avg loss: 2.5525 \n",
      "\n",
      "Epoch: 2 Train_loss: 0.11822104861494154 Valid_loss: 2.5525479316711426 Valid_acc: 0.45524296164512634\n",
      " epoch 3 loss: 0.0781\n",
      "0.000979746486807249\n",
      "Epoch [3], Train Loss: 0.0753, \n",
      "3119/3188 train accuracy 0.9783563017845154\n",
      "176/391 accuracy 0.45012786984443665\n",
      "Test Error: \n",
      "   Accuracy: 45.01, Avg loss: 2.8705 \n",
      "\n",
      "Epoch: 3 Train_loss: 0.07531936213490553 Valid_loss: 2.870485782623291 Valid_acc: 0.45012786984443665\n",
      " epoch 4 loss: 0.0402\n",
      "0.0009548159976772593\n",
      "Epoch [4], Train Loss: 0.0491, \n",
      "3140/3188 train accuracy 0.9849435091018677\n",
      "138/391 accuracy 0.3529411852359772\n",
      "Test Error: \n",
      "   Accuracy: 35.29, Avg loss: 4.7833 \n",
      "\n",
      "Epoch: 4 Train_loss: 0.04907795225153677 Valid_loss: 4.783266544342041 Valid_acc: 0.3529411852359772\n",
      " epoch 5 loss: 0.0491\n",
      "0.0009206267664155907\n",
      "Epoch [5], Train Loss: 0.0487, \n",
      "3143/3188 train accuracy 0.9858845472335815\n",
      "164/391 accuracy 0.41943734884262085\n",
      "Test Error: \n",
      "   Accuracy: 41.94, Avg loss: 3.5027 \n",
      "\n",
      "Epoch: 5 Train_loss: 0.048677911749109626 Valid_loss: 3.5026955604553223 Valid_acc: 0.41943734884262085\n",
      " epoch 6 loss: 0.0286\n",
      "0.0008778747871771292\n",
      "Epoch [6], Train Loss: 0.0303, \n",
      "3156/3188 train accuracy 0.9899623394012451\n",
      "175/391 accuracy 0.4475703239440918\n",
      "Test Error: \n",
      "   Accuracy: 44.76, Avg loss: 2.9807 \n",
      "\n",
      "Epoch: 6 Train_loss: 0.030267176043707877 Valid_loss: 2.9807255268096924 Valid_acc: 0.4475703239440918\n",
      " epoch 7 loss: 0.0254\n",
      "0.0008274303669726427\n",
      "Epoch [7], Train Loss: 0.0259, \n",
      "3163/3188 train accuracy 0.992158055305481\n",
      "191/391 accuracy 0.4884910583496094\n",
      "Test Error: \n",
      "   Accuracy: 48.85, Avg loss: 3.0467 \n",
      "\n",
      "Epoch: 7 Train_loss: 0.02585507278854493 Valid_loss: 3.0466842651367188 Valid_acc: 0.4884910583496094\n",
      " epoch 8 loss: 0.0191\n",
      "0.0007703204087277989\n",
      "Epoch [8], Train Loss: 0.0237, \n",
      "3163/3188 train accuracy 0.992158055305481\n",
      "165/391 accuracy 0.4219948947429657\n",
      "Test Error: \n",
      "   Accuracy: 42.20, Avg loss: 4.3751 \n",
      "\n",
      "Epoch: 8 Train_loss: 0.023673602838243823 Valid_loss: 4.37513542175293 Valid_acc: 0.4219948947429657\n",
      " epoch 9 loss: 0.0215\n",
      "0.0007077075065009433\n",
      "Epoch [9], Train Loss: 0.0240, \n",
      "3165/3188 train accuracy 0.9927854537963867\n",
      "151/391 accuracy 0.3861892521381378\n",
      "Test Error: \n",
      "   Accuracy: 38.62, Avg loss: 4.1306 \n",
      "\n",
      "Epoch: 9 Train_loss: 0.024033786561631132 Valid_loss: 4.130566120147705 Valid_acc: 0.3861892521381378\n",
      " epoch 10 loss: 0.0180\n",
      "0.0006408662784207149\n",
      "Epoch [10], Train Loss: 0.0183, \n",
      "3169/3188 train accuracy 0.9940401315689087\n",
      "175/391 accuracy 0.4475703239440918\n",
      "Test Error: \n",
      "   Accuracy: 44.76, Avg loss: 4.1036 \n",
      "\n",
      "Epoch: 10 Train_loss: 0.018304664168681484 Valid_loss: 4.10361909866333 Valid_acc: 0.4475703239440918\n",
      " epoch 11 loss: 0.0112\n",
      "0.0005711574191366426\n",
      "Epoch [11], Train Loss: 0.0105, \n",
      "3177/3188 train accuracy 0.9965495467185974\n",
      "192/391 accuracy 0.49104857444763184\n",
      "Test Error: \n",
      "   Accuracy: 49.10, Avg loss: 3.4126 \n",
      "\n",
      "Epoch: 11 Train_loss: 0.01050476295131375 Valid_loss: 3.4126017093658447 Valid_acc: 0.49104857444763184\n",
      " epoch 12 loss: 0.0109\n",
      "0.0005000000000000002\n",
      "Epoch [12], Train Loss: 0.0104, \n",
      "3178/3188 train accuracy 0.9968632459640503\n",
      "184/391 accuracy 0.47058823704719543\n",
      "Test Error: \n",
      "   Accuracy: 47.06, Avg loss: 3.9816 \n",
      "\n",
      "Epoch: 12 Train_loss: 0.010361317590650287 Valid_loss: 3.9816370010375977 Valid_acc: 0.47058823704719543\n",
      " epoch 13 loss: 0.0093\n",
      "0.00042884258086335755\n",
      "Epoch [13], Train Loss: 0.0094, \n",
      "3179/3188 train accuracy 0.9971768856048584\n",
      "181/391 accuracy 0.4629155993461609\n",
      "Test Error: \n",
      "   Accuracy: 46.29, Avg loss: 4.0317 \n",
      "\n",
      "Epoch: 13 Train_loss: 0.009354446203360567 Valid_loss: 4.031748294830322 Valid_acc: 0.4629155993461609\n",
      " epoch 14 loss: 0.0086\n",
      "0.0003591337215792852\n",
      "Epoch [14], Train Loss: 0.0098, \n",
      "3177/3188 train accuracy 0.9965495467185974\n",
      "184/391 accuracy 0.47058823704719543\n",
      "Test Error: \n",
      "   Accuracy: 47.06, Avg loss: 4.2873 \n",
      "\n",
      "Epoch: 14 Train_loss: 0.009804424980757176 Valid_loss: 4.287259101867676 Valid_acc: 0.47058823704719543\n",
      " epoch 15 loss: 0.0090\n",
      "0.00029229249349905687\n",
      "Epoch [15], Train Loss: 0.0076, \n",
      "3182/3188 train accuracy 0.9981179237365723\n",
      "186/391 accuracy 0.47570332884788513\n",
      "Test Error: \n",
      "   Accuracy: 47.57, Avg loss: 4.0489 \n",
      "\n",
      "Epoch: 15 Train_loss: 0.007643158491191571 Valid_loss: 4.048913478851318 Valid_acc: 0.47570332884788513\n",
      " epoch 16 loss: 0.0063\n",
      "0.00022967959127220141\n",
      "Epoch [16], Train Loss: 0.0054, \n",
      "3182/3188 train accuracy 0.9981179237365723\n",
      "179/391 accuracy 0.4578005075454712\n",
      "Test Error: \n",
      "   Accuracy: 45.78, Avg loss: 4.2982 \n",
      "\n",
      "Epoch: 16 Train_loss: 0.005430881175925606 Valid_loss: 4.29824161529541 Valid_acc: 0.4578005075454712\n",
      " epoch 17 loss: 0.0054\n",
      "0.00017256963302735752\n",
      "Epoch [17], Train Loss: 0.0049, \n",
      "3186/3188 train accuracy 0.999372661113739\n",
      "186/391 accuracy 0.47570332884788513\n",
      "Test Error: \n",
      "   Accuracy: 47.57, Avg loss: 3.9050 \n",
      "\n",
      "Epoch: 17 Train_loss: 0.004937784163303149 Valid_loss: 3.9049808979034424 Valid_acc: 0.47570332884788513\n",
      " epoch 18 loss: 0.0021\n",
      "0.00012212521282287095\n",
      "Epoch [18], Train Loss: 0.0034, \n",
      "3186/3188 train accuracy 0.999372661113739\n",
      "185/391 accuracy 0.4731457829475403\n",
      "Test Error: \n",
      "   Accuracy: 47.31, Avg loss: 4.0856 \n",
      "\n",
      "Epoch: 18 Train_loss: 0.00337960732395004 Valid_loss: 4.085569381713867 Valid_acc: 0.4731457829475403\n",
      " epoch 19 loss: 0.0030\n",
      "7.937323358440948e-05\n",
      "Epoch [19], Train Loss: 0.0027, \n",
      "3186/3188 train accuracy 0.999372661113739\n",
      "186/391 accuracy 0.47570332884788513\n",
      "Test Error: \n",
      "   Accuracy: 47.57, Avg loss: 4.1782 \n",
      "\n",
      "Epoch: 19 Train_loss: 0.0027144196847075364 Valid_loss: 4.178191661834717 Valid_acc: 0.47570332884788513\n",
      " epoch 20 loss: 0.0055\n",
      "4.5184002322740903e-05\n",
      "Epoch [20], Train Loss: 0.0046, \n",
      "3183/3188 train accuracy 0.9984316229820251\n",
      "185/391 accuracy 0.4731457829475403\n",
      "Test Error: \n",
      "   Accuracy: 47.31, Avg loss: 4.1630 \n",
      "\n",
      "Epoch: 20 Train_loss: 0.004633101764738967 Valid_loss: 4.163024425506592 Valid_acc: 0.4731457829475403\n",
      " epoch 21 loss: 0.0019\n",
      "2.0253513192751323e-05\n",
      "Epoch [21], Train Loss: 0.0028, \n",
      "3187/3188 train accuracy 0.9996863007545471\n",
      "189/391 accuracy 0.4833759665489197\n",
      "Test Error: \n",
      "   Accuracy: 48.34, Avg loss: 4.1521 \n",
      "\n",
      "Epoch: 21 Train_loss: 0.0028066588120054803 Valid_loss: 4.152110576629639 Valid_acc: 0.4833759665489197\n",
      " epoch 22 loss: 0.0017\n",
      "5.08927905953366e-06\n",
      "Epoch [22], Train Loss: 0.0017, \n",
      "3188/3188 train accuracy 1.0\n",
      "184/391 accuracy 0.47058823704719543\n",
      "Test Error: \n",
      "   Accuracy: 47.06, Avg loss: 4.1311 \n",
      "\n",
      "Epoch: 22 Train_loss: 0.0017220685904248967 Valid_loss: 4.131147861480713 Valid_acc: 0.47058823704719543\n",
      " epoch 23 loss: 0.0015\n",
      "0.0\n",
      "Epoch [23], Train Loss: 0.0014, \n",
      "3188/3188 train accuracy 1.0\n",
      "188/391 accuracy 0.48081842064857483\n",
      "Test Error: \n",
      "   Accuracy: 48.08, Avg loss: 4.1389 \n",
      "\n",
      "Epoch: 23 Train_loss: 0.0014263246721384348 Valid_loss: 4.138926982879639 Valid_acc: 0.48081842064857483\n",
      " epoch 24 loss: 0.0018\n",
      "5.089279059533658e-06\n",
      "Epoch [24], Train Loss: 0.0018, \n",
      "3187/3188 train accuracy 0.9996863007545471\n",
      "186/391 accuracy 0.47570332884788513\n",
      "Test Error: \n",
      "   Accuracy: 47.57, Avg loss: 4.2277 \n",
      "\n",
      "Epoch: 24 Train_loss: 0.0018380959563728538 Valid_loss: 4.227686405181885 Valid_acc: 0.47570332884788513\n",
      " epoch 25 loss: 0.0012\n",
      "2.0253513192751482e-05\n",
      "Epoch [25], Train Loss: 0.0015, \n",
      "3188/3188 train accuracy 1.0\n",
      "180/391 accuracy 0.46035805344581604\n",
      "Test Error: \n",
      "   Accuracy: 46.04, Avg loss: 4.4064 \n",
      "\n",
      "Epoch: 25 Train_loss: 0.001490699317855615 Valid_loss: 4.406437397003174 Valid_acc: 0.46035805344581604\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "rn34_model.to(device)\n",
    "\n",
    "## Optimizer construction using Adam.\n",
    "params = [p for p in rn34_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params,\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "lr_optimizer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(epochs*0.9))\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# ******************* TensorBoard *******************\n",
    "writer = SummaryWriter(comment=\"REAL-ass2\")\n",
    "\n",
    "# ******************* Optimization *******************\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    # set the module in training mode.\n",
    "    rn34_model.train()\n",
    "    train_loss, train_acc = train(dl_train_real, rn34_model, loss_fn, optimizer, lr_optimizer, epoch, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train_acc', train_acc, epoch)\n",
    "\n",
    "    # save model weights\n",
    "    save_path = 'ckpt_{:04d}.pth'.format(epoch+1)\n",
    "    torch.save(rn34_model.state_dict(), save_path)\n",
    "\n",
    "    # validation loop\n",
    "    # set the module in evaluation mode.\n",
    "    rn34_model.eval()\n",
    "    valid_loss, valid_accuracy = test(dl_valid_sketch, rn34_model, loss_fn, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('valid_loss', valid_loss, epoch)\n",
    "    writer.add_scalar('valid_accuracy', valid_accuracy, epoch)\n",
    "\n",
    "    writer.add_scalars('losses', {'train_loss':train_loss,\n",
    "                                  'valid_loss':valid_loss}, epoch)\n",
    "    \n",
    "    writer.add_scalars('accuracy', {'train_acc':train_acc,\n",
    "                                  'valid_acc':valid_accuracy}, epoch)\n",
    "\n",
    "    if valid_accuracy > best_accuracy:    # save the model with best validation accuracy\n",
    "        save_path = 'ckpt_best.pth'\n",
    "        torch.save(rn34_model.state_dict(), save_path)\n",
    "        best_accuracy = valid_accuracy\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}', f'Train_loss: {train_loss}', f'Valid_loss: {valid_loss}', f'Valid_acc: {valid_accuracy}')\n",
    "\n",
    "writer.close()\n",
    "print(\"Finished Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/841 accuracy 0.43281805515289307\n",
      "Test Error: \n",
      "   Accuracy: 43.28, Avg loss: 4.5012 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rn34_model.to(device)\n",
    "rn34_model.eval()\n",
    "valid_loss, valid_accuracy = test(dl_test_sketch, rn34_model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_loss_weight = 10\n",
    "mmd_loss_weight = 1e-2\n",
    "epochs = 20\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMD(torch.nn.Module):\n",
    "    def forward(self, source, target):\n",
    "        print(source.shape, target.shape)\n",
    "        mSource = source.mean()\n",
    "        mTarget = target.mean()\n",
    "        L2_dist = torch.square(torch.linalg.vector_norm(mSource-mTarget))\n",
    "\n",
    "        return L2_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_kernels=5, mul_factor=2.0, bandwidth=None):\n",
    "        super().__init__()\n",
    "        self.bandwidth_multipliers = mul_factor ** (torch.arange(n_kernels) - n_kernels // 2).to(device)\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "    def get_bandwidth(self, L2_distances):\n",
    "        if self.bandwidth is None:\n",
    "            n_samples = L2_distances.shape[0]\n",
    "            return L2_distances.data.sum() / (n_samples ** 2 - n_samples)\n",
    "\n",
    "        return self.bandwidth\n",
    "\n",
    "    def forward(self, X):\n",
    "        L2_distances = torch.cdist(X, X) ** 2\n",
    "        return torch.exp(-L2_distances[None, ...] / (self.get_bandwidth(L2_distances) * self.bandwidth_multipliers)[:, None, None]).sum(dim=0)\n",
    "\n",
    "\n",
    "class MMDLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, kernel=RBF()):\n",
    "        super().__init__()\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        K = self.kernel(torch.vstack([X, Y]))\n",
    "\n",
    "        X_size = X.shape[0]\n",
    "        XX = K[:X_size, :X_size].mean()\n",
    "        XY = K[:X_size, X_size:].mean()\n",
    "        YY = K[X_size:, X_size:].mean()\n",
    "        return XX - 2 * XY + YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CORAL(torch.nn.Module):\n",
    "    def forward(self, source, target):\n",
    "        d = source.size(1)\n",
    "        source_cov = torch.cov(source.t())\n",
    "        target_cov = torch.cov(target.t())\n",
    "        loss = torch.trace(torch.mm(source_cov-target_cov, (source_cov-target_cov).t()))\n",
    "        loss = loss / (4*d*d)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_coral(src_loader, tgt_loader, model, loss_fn, optimizer, lr_optimizer, epoch, device):\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    train_steps = min(len(src_loader), len(tgt_loader))\n",
    "\n",
    "    #mmd_fn = MMDLoss()\n",
    "    coral_fn = CORAL()\n",
    "\n",
    "    for idx in range(train_steps):\n",
    "        src_input, src_label = next(iter(src_loader))\n",
    "        tgt_input, _ = next(iter(tgt_loader))\n",
    "\n",
    "        src_input = src_input.to(device)\n",
    "        src_label = src_label.to(device)\n",
    "        tgt_input = tgt_input.to(device)\n",
    "\n",
    "        src_outputs = model(src_input)\n",
    "        tgt_outputs = model(tgt_input)\n",
    "\n",
    "        loss = loss_fn(src_outputs['fc'], src_label)\n",
    "\n",
    "        #loss_mmd = mmd_fn(src_outputs['flatten'], tgt_outputs['flatten'])\n",
    "\n",
    "        loss_coral = coral_fn(src_outputs['flatten'], tgt_outputs['flatten'])\n",
    "\n",
    "        joint_loss = loss + coral_loss_weight*loss_coral\n",
    "        print(joint_loss, loss_coral, loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        joint_loss.backward()\n",
    "        # update the parameters according to gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += joint_loss.item()\n",
    "        train_loss += joint_loss.item()\n",
    "\n",
    "        # report every 100 iterations\n",
    "        if idx % 25 == 24:\n",
    "            print(' epoch {} loss: {:.4f}'.format(epoch+1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    print(optimizer.param_groups[0][\"lr\"])\n",
    "    lr_optimizer.step()\n",
    "    \n",
    "    train_loss = train_loss/train_steps\n",
    "\n",
    "    print(f'Epoch [{epoch+1}], '\n",
    "          f'Train Loss: {train_loss:.4f}, ')\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "def test_coral(src_loader, model, loss_fn, device):\n",
    "\n",
    "    valid_loss = 0\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in src_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            scores = model(data)['fc']\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "            valid_loss += loss_fn(scores, targets)\n",
    "        \n",
    "        print(f'{num_correct}/{num_samples} accuracy {num_correct/num_samples}')\n",
    "\n",
    "    # Gather data and report\n",
    "    valid_loss /= len(src_loader)\n",
    "    accuracy = num_correct/num_samples\n",
    "    print(\"Test Error: \\n   Accuracy: {:.2f}, Avg loss: {:.4f} \\n\".format(100*accuracy, valid_loss))\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaskRCNN requires a backbone with an attached FPN\n",
    "class Resnet34(torch.nn.Module):\n",
    "    def __init__(self, return_nodes, num_classes):\n",
    "        super(Resnet34, self).__init__()\n",
    "        # Get a resnet34 backbone\n",
    "        m = models.resnet34(weights='DEFAULT')\n",
    "        # Print all evaluation layer names.\n",
    "        _, eval_nodes = get_graph_node_names(m)\n",
    "        #print(eval_nodes)\n",
    "        m.fc = torch.nn.Linear(m.fc.in_features, num_classes)\n",
    "        # Extract 4 main layers\n",
    "        self.body = create_feature_extractor(\n",
    "            m, return_nodes=return_nodes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_nodes = {\n",
    "    'flatten':'flatten',\n",
    "    'fc':'fc'\n",
    "}\n",
    "rn34_model = Resnet34(return_nodes, 10)\n",
    "\n",
    "# Freeze all gradients on parameters.\n",
    "for p in rn34_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Thaw gradients for layer 4.\n",
    "for parameter in rn34_model.body.layer4.parameters():\n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.7244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.6116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5814, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.5362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2430, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.1948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1758, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9465, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.8993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.7112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5516, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.5030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.3204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.2020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8992, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.8469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6604, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0063, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7361, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0062, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5432, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4261, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0079, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4748, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3491, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0082, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3003, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 1 loss: 0.2907\n",
      "tensor(0.2480, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2492, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0072, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0086, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2093, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.01\n",
      "Epoch [1], Train Loss: 0.9668, \n",
      "234/391 accuracy 0.5984654426574707\n",
      "Test Error: \n",
      "   Accuracy: 59.85, Avg loss: 1.4779 \n",
      "\n",
      "Epoch: 1 Train_loss: 0.9667513309977949 Valid_loss: 1.4778594970703125 Valid_acc: 0.5984654426574707\n",
      "tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0074, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1628, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0075, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0072, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0069, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0073, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2921, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2098, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0068, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0068, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0072, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2747, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0072, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0061, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0067, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0071, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0062, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 2 loss: 0.0541\n",
      "tensor(0.1924, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0060, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0067, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0067, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0061, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0061, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.00992403876506104\n",
      "Epoch [2], Train Loss: 0.2065, \n",
      "242/391 accuracy 0.6189258098602295\n",
      "Test Error: \n",
      "   Accuracy: 61.89, Avg loss: 1.4444 \n",
      "\n",
      "Epoch: 2 Train_loss: 0.20654808403924108 Valid_loss: 1.4443767070770264 Valid_acc: 0.6189258098602295\n",
      "tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1620, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0064, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0063, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1404, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0065, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0070, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0061, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0063, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0062, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1197, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 3 loss: 0.0407\n",
      "tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0056, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.009698463103929541\n",
      "Epoch [3], Train Loss: 0.1586, \n",
      "227/391 accuracy 0.5805626511573792\n",
      "Test Error: \n",
      "   Accuracy: 58.06, Avg loss: 1.6068 \n",
      "\n",
      "Epoch: 3 Train_loss: 0.15863712830469012 Valid_loss: 1.6068079471588135 Valid_acc: 0.5805626511573792\n",
      "tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1311, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0066, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0059, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1287, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1205, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0055, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 4 loss: 0.0333\n",
      "tensor(0.0998, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.009330127018922192\n",
      "Epoch [4], Train Loss: 0.1306, \n",
      "243/391 accuracy 0.6214833855628967\n",
      "Test Error: \n",
      "   Accuracy: 62.15, Avg loss: 1.5322 \n",
      "\n",
      "Epoch: 4 Train_loss: 0.13057640753686428 Valid_loss: 1.5322185754776 Valid_acc: 0.6214833855628967\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1271, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 5 loss: 0.0281\n",
      "tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.008830222215594888\n",
      "Epoch [5], Train Loss: 0.1089, \n",
      "239/391 accuracy 0.6112532019615173\n",
      "Test Error: \n",
      "   Accuracy: 61.13, Avg loss: 1.6074 \n",
      "\n",
      "Epoch: 5 Train_loss: 0.10892055230215192 Valid_loss: 1.6074265241622925 Valid_acc: 0.6112532019615173\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0050, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0753, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1451, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1132, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0051, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 6 loss: 0.0261\n",
      "tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0054, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0861, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.008213938048432694\n",
      "Epoch [6], Train Loss: 0.1019, \n",
      "234/391 accuracy 0.5984654426574707\n",
      "Test Error: \n",
      "   Accuracy: 59.85, Avg loss: 1.6740 \n",
      "\n",
      "Epoch: 6 Train_loss: 0.10187800321727991 Valid_loss: 1.6740062236785889 Valid_acc: 0.5984654426574707\n",
      "tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1394, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0053, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0954, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0049, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 7 loss: 0.0215\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1438, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.007499999999999998\n",
      "Epoch [7], Train Loss: 0.0850, \n",
      "239/391 accuracy 0.6112532019615173\n",
      "Test Error: \n",
      "   Accuracy: 61.13, Avg loss: 1.6414 \n",
      "\n",
      "Epoch: 7 Train_loss: 0.0849629808217287 Valid_loss: 1.641394019126892 Valid_acc: 0.6112532019615173\n",
      "tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1127, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 8 loss: 0.0214\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.006710100716628343\n",
      "Epoch [8], Train Loss: 0.0841, \n",
      "234/391 accuracy 0.5984654426574707\n",
      "Test Error: \n",
      "   Accuracy: 59.85, Avg loss: 1.8207 \n",
      "\n",
      "Epoch: 8 Train_loss: 0.08409180562011898 Valid_loss: 1.8207406997680664 Valid_acc: 0.5984654426574707\n",
      "tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0045, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0048, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 9 loss: 0.0179\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.005868240888334651\n",
      "Epoch [9], Train Loss: 0.0726, \n",
      "239/391 accuracy 0.6112532019615173\n",
      "Test Error: \n",
      "   Accuracy: 61.13, Avg loss: 1.6860 \n",
      "\n",
      "Epoch: 9 Train_loss: 0.07258251553867012 Valid_loss: 1.68595552444458 Valid_acc: 0.6112532019615173\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0843, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0047, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 10 loss: 0.0178\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0804, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.004999999999999998\n",
      "Epoch [10], Train Loss: 0.0704, \n",
      "236/391 accuracy 0.6035805344581604\n",
      "Test Error: \n",
      "   Accuracy: 60.36, Avg loss: 1.6847 \n",
      "\n",
      "Epoch: 10 Train_loss: 0.07035181706305593 Valid_loss: 1.6846791505813599 Valid_acc: 0.6035805344581604\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 11 loss: 0.0175\n",
      "tensor(0.0815, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.004131759111665347\n",
      "Epoch [11], Train Loss: 0.0706, \n",
      "228/391 accuracy 0.5831202268600464\n",
      "Test Error: \n",
      "   Accuracy: 58.31, Avg loss: 1.7451 \n",
      "\n",
      "Epoch: 11 Train_loss: 0.07059421087615192 Valid_loss: 1.745104432106018 Valid_acc: 0.5831202268600464\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0550, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 12 loss: 0.0162\n",
      "tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0032898992833716566\n",
      "Epoch [12], Train Loss: 0.0655, \n",
      "238/391 accuracy 0.6086956262588501\n",
      "Test Error: \n",
      "   Accuracy: 60.87, Avg loss: 1.6543 \n",
      "\n",
      "Epoch: 12 Train_loss: 0.06549486075527966 Valid_loss: 1.6543384790420532 Valid_acc: 0.6086956262588501\n",
      "tensor(0.0993, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 13 loss: 0.0155\n",
      "tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0025000000000000005\n",
      "Epoch [13], Train Loss: 0.0637, \n",
      "240/391 accuracy 0.6138107180595398\n",
      "Test Error: \n",
      "   Accuracy: 61.38, Avg loss: 1.6721 \n",
      "\n",
      "Epoch: 13 Train_loss: 0.06369056750554591 Valid_loss: 1.6721312999725342 Valid_acc: 0.6138107180595398\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 14 loss: 0.0154\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0017860619515673026\n",
      "Epoch [14], Train Loss: 0.0619, \n",
      "244/391 accuracy 0.6240409016609192\n",
      "Test Error: \n",
      "   Accuracy: 62.40, Avg loss: 1.6450 \n",
      "\n",
      "Epoch: 14 Train_loss: 0.06185092648956925 Valid_loss: 1.6450015306472778 Valid_acc: 0.6240409016609192\n",
      "tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0562, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0698, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 15 loss: 0.0161\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0011697777844051102\n",
      "Epoch [15], Train Loss: 0.0648, \n",
      "241/391 accuracy 0.616368293762207\n",
      "Test Error: \n",
      "   Accuracy: 61.64, Avg loss: 1.6272 \n",
      "\n",
      "Epoch: 15 Train_loss: 0.06481227069161832 Valid_loss: 1.6271902322769165 Valid_acc: 0.616368293762207\n",
      "tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0598, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 16 loss: 0.0159\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0006698729810778074\n",
      "Epoch [16], Train Loss: 0.0632, \n",
      "237/391 accuracy 0.6061381101608276\n",
      "Test Error: \n",
      "   Accuracy: 60.61, Avg loss: 1.7166 \n",
      "\n",
      "Epoch: 16 Train_loss: 0.06315417389851063 Valid_loss: 1.7165776491165161 Valid_acc: 0.6061381101608276\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0672, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 17 loss: 0.0156\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0003015368960704583\n",
      "Epoch [17], Train Loss: 0.0625, \n",
      "237/391 accuracy 0.6061381101608276\n",
      "Test Error: \n",
      "   Accuracy: 60.61, Avg loss: 1.6809 \n",
      "\n",
      "Epoch: 17 Train_loss: 0.06245260243304074 Valid_loss: 1.6808992624282837 Valid_acc: 0.6061381101608276\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0560, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 18 loss: 0.0156\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7.596123493895987e-05\n",
      "Epoch [18], Train Loss: 0.0622, \n",
      "240/391 accuracy 0.6138107180595398\n",
      "Test Error: \n",
      "   Accuracy: 61.38, Avg loss: 1.6518 \n",
      "\n",
      "Epoch: 18 Train_loss: 0.06215710437390953 Valid_loss: 1.6518421173095703 Valid_acc: 0.6138107180595398\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0744, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0028, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 19 loss: 0.0152\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "0.0\n",
      "Epoch [19], Train Loss: 0.0607, \n",
      "239/391 accuracy 0.6112532019615173\n",
      "Test Error: \n",
      "   Accuracy: 61.13, Avg loss: 1.7743 \n",
      "\n",
      "Epoch: 19 Train_loss: 0.06074236170388758 Valid_loss: 1.774289608001709 Valid_acc: 0.6112532019615173\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0044, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0037, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0032, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0038, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0040, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0034, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " epoch 20 loss: 0.0164\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0029, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0036, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0039, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7.59612349389599e-05\n",
      "Epoch [20], Train Loss: 0.0644, \n",
      "242/391 accuracy 0.6189258098602295\n",
      "Test Error: \n",
      "   Accuracy: 61.89, Avg loss: 1.7190 \n",
      "\n",
      "Epoch: 20 Train_loss: 0.06439908023457974 Valid_loss: 1.7189911603927612 Valid_acc: 0.6189258098602295\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# Run on CUDA/GPU\n",
    "rn34_model.to(device)\n",
    "\n",
    "## Optimizer construction using SGD\n",
    "params = [p for p in rn34_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=5e-4,\n",
    "    momentum=0.9\n",
    ")\n",
    "lr_optimizer = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(epochs*0.9))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# ******************* TensorBoard *******************\n",
    "writer = SummaryWriter(comment=\"CORAL-ass2\")\n",
    "\n",
    "# ******************* Optimization *******************\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    # set the module in training mode.\n",
    "    rn34_model.train()\n",
    "    train_loss = train_coral(dl_train_real, dl_train_sketch, rn34_model, loss_fn, optimizer, lr_optimizer, epoch, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "\n",
    "    # save model weights\n",
    "    save_path = 'ckpt_{:04d}_22.pth'.format(epoch+1)\n",
    "    torch.save(rn34_model.state_dict(), save_path)\n",
    "\n",
    "    # validation loop\n",
    "    # set the module in evaluation mode.\n",
    "    rn34_model.eval()\n",
    "    valid_loss, valid_accuracy = test_coral(dl_valid_sketch, rn34_model, loss_fn, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('valid_loss', valid_loss, epoch)\n",
    "    writer.add_scalar('valid_accuracy', valid_accuracy, epoch)\n",
    "\n",
    "    writer.add_scalars('losses', {'train_loss':train_loss,\n",
    "                                  'valid_loss':valid_loss}, epoch)\n",
    "    \n",
    "    writer.add_scalars('accuracy', {'valid_acc':valid_accuracy}, epoch)\n",
    "\n",
    "    if valid_accuracy > best_accuracy:    # save the model with best validation accuracy\n",
    "        save_path = 'ckpt_best_22.pth'\n",
    "        torch.save(rn34_model.state_dict(), save_path)\n",
    "        best_accuracy = valid_accuracy\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}', f'Train_loss: {train_loss}', f'Valid_loss: {valid_loss}', f'Valid_acc: {valid_accuracy}')\n",
    "\n",
    "writer.close()\n",
    "print(\"Finished Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/841 accuracy 0.587395966053009\n",
      "Test Error: \n",
      "   Accuracy: 58.74, Avg loss: 1.7610 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rn34_model.to(device)\n",
    "rn34_model.eval()\n",
    "valid_loss, valid_accuracy = test_coral(dl_test_sketch, rn34_model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
