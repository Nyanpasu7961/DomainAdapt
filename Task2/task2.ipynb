{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_label= {\n",
    "    0: \"backpack\",\n",
    "    1: \"book\",\n",
    "    2: \"car\",\n",
    "    3: \"pizza\",\n",
    "    4: \"sandwich\",\n",
    "    5: \"snake\",\n",
    "    6: \"sock\",\n",
    "    7: \"tiger\",\n",
    "    8: \"tree\",\n",
    "    9: \"watermelon\"\n",
    "}\n",
    "\n",
    "label_to_num = dict((v,k) for k,v in num_to_label.items())\n",
    "\n",
    "def obtain_labels(root_dir):\n",
    "    labels = []\n",
    "\n",
    "    ok = os.walk(root_dir, topdown=False)\n",
    "    for root, _, files in ok:\n",
    "        if root_dir == root: continue\n",
    "        root = os.path.basename(root)\n",
    "        labels += list(map(lambda x: [x, root], files))\n",
    "\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = obtain_labels(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx, 1], self.img_labels[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "dataset_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "class LabelToNum(torch.nn.Module):\n",
    "    def forward(self, label):\n",
    "        return label_to_num[label]\n",
    "\n",
    "label_transform = LabelToNum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn34_model = models.resnet34()\n",
    "num_ftrs = rn34_model.fc.in_features\n",
    "rn34_model.fc = torch.nn.Linear(num_ftrs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_valid(dataset, validation_split=0.2, random_seed=42):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    return train_sampler, valid_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain Real datasets and split for validation sets.\n",
    "train_dataset_real = CustomImageDataset(img_dir=\"data/real_train\", transform=dataset_transform, target_transform=label_transform)\n",
    "test_dataset_real = CustomImageDataset(img_dir=\"data/real_test\", transform=dataset_transform, target_transform=label_transform)\n",
    "\n",
    "## Obtain Sketch datasets and split for validation sets.\n",
    "train_dataset_sketch = CustomImageDataset(img_dir=\"data/sketch_train\", transform=dataset_transform, target_transform=label_transform)\n",
    "test_dataset_sketch = CustomImageDataset(img_dir=\"data/sketch_test\", transform=dataset_transform, target_transform=label_transform)\n",
    "\n",
    "t_real_sample, v_real_sample = split_valid(train_dataset_real)\n",
    "t_sketch_sample, v_sketch_sample = split_valid(train_dataset_sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(src_loader, model, loss_fn, optimizer, epoch, device):\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "   \n",
    "    for idx, (data, targets) in enumerate(src_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters according to gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # report every 100 iterations\n",
    "        if idx % 25 == 24:\n",
    "            print(' epoch {} loss: {:.4f}'.format(epoch+1, running_loss / 25))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    train_loss = train_loss/(idx+1)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}], '\n",
    "          f'Train Loss: {train_loss:.4f}, ')\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(src_loader, model, loss_fn, device):\n",
    "\n",
    "    valid_loss = 0\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in src_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            scores = model(data)['fc']\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "            valid_loss += loss_fn(scores, targets)\n",
    "        \n",
    "        print(f'{num_correct}/{num_samples} accuracy {num_correct/num_samples}')\n",
    "\n",
    "    # Gather data and report\n",
    "    valid_loss /= len(src_loader)\n",
    "    accuracy = num_correct/num_samples\n",
    "    print(\"Test Error: \\n   Accuracy: {:.2f}, Avg loss: {:.4f} \\n\".format(100*accuracy, valid_loss))\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Training init\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real DataLoaders\n",
    "dl_train_real = DataLoader(\n",
    "    train_dataset_real,\n",
    "    batch_size=batch_size,\n",
    "    sampler=t_real_sample,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "dl_valid_real = DataLoader(\n",
    "    train_dataset_real,\n",
    "    batch_size=batch_size,\n",
    "    sampler=v_real_sample,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "dl_test_real = DataLoader(\n",
    "    test_dataset_real,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "## Sketch DataLoaders\n",
    "dl_train_sketch = DataLoader(\n",
    "    train_dataset_sketch,\n",
    "    batch_size=batch_size,\n",
    "    sampler=t_sketch_sample,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "dl_valid_sketch = DataLoader(\n",
    "    train_dataset_sketch,\n",
    "    batch_size=batch_size,\n",
    "    sampler=v_sketch_sample,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "dl_test_sketch = DataLoader(\n",
    "    test_dataset_sketch,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# train loop\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# set the module in training mode.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     rn34_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 19\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train_sketch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrn34_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# save to tensorboard\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, train_loss, epoch)\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(src_loader, model, loss_fn, optimizer, epoch, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Gather data and report\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# report every 100 iterations\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Optimizer construction using Adam.\n",
    "params = [p for p in rn34_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(\n",
    "    params,\n",
    "    lr=learning_rate,\n",
    ")\n",
    "rn34_model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# ******************* TensorBoard *******************\n",
    "writer = SummaryWriter(comment=\"ass2\")\n",
    "\n",
    "# ******************* Optimization *******************\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    # set the module in training mode.\n",
    "    rn34_model.train()\n",
    "    train_loss = train(dl_train_sketch, rn34_model, loss_fn, optimizer, epoch, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "\n",
    "    # save model weights\n",
    "    save_path = 'ckpt_{:04d}_22.pth'.format(epoch+1)\n",
    "    torch.save(rn34_model.state_dict(), save_path)\n",
    "\n",
    "    # validation loop\n",
    "    # set the module in evaluation mode.\n",
    "    rn34_model.eval()\n",
    "    valid_loss, valid_accuracy = test(dl_valid_sketch, rn34_model, loss_fn, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('valid_loss', valid_loss, epoch)\n",
    "    writer.add_scalar('valid_accuracy', valid_accuracy, epoch)\n",
    "\n",
    "    if valid_accuracy > best_accuracy:    # save the model with best validation accuracy\n",
    "        save_path = 'ckpt_best_22.pth'\n",
    "        torch.save(rn34_model.state_dict(), save_path)\n",
    "        best_accuracy = valid_accuracy\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}', f'Train_loss: {train_loss}', f'Valid_loss: {valid_loss}', f'Valid_acc: {valid_accuracy}')\n",
    "\n",
    "writer.close()\n",
    "print(\"Finished Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_loss_weight = 10\n",
    "epochs = 20\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CORAL(torch.nn.Module):\n",
    "    def forward(self, source, target):\n",
    "        d = source.size(1)\n",
    "        source_cov = torch.cov(source.t(), correction=1)\n",
    "        target_cov = torch.cov(target.t(), correction=1)\n",
    "        loss = torch.square(torch.norm(source_cov-target_cov, p='fro'))\n",
    "        loss = loss / (4*d*d)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_coral(src_loader, tgt_loader, model, loss_fn, optimizer, epoch, device):\n",
    "    running_loss = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    train_steps = min(len(src_loader), len(tgt_loader))\n",
    "\n",
    "    coral = CORAL()\n",
    "\n",
    "    for idx in range(train_steps):\n",
    "        src_input, src_label = next(iter(src_loader))\n",
    "        tgt_input, _ = next(iter(tgt_loader))\n",
    "\n",
    "        src_input = src_input.to(device)\n",
    "        src_label = src_label.to(device)\n",
    "        tgt_input = tgt_input.to(device)\n",
    "\n",
    "        src_outputs = model(src_input)\n",
    "        tgt_outputs = model(tgt_input)\n",
    "\n",
    "        loss = loss_fn(src_outputs['fc'], src_label)\n",
    "\n",
    "        loss_coral = coral(src_outputs['flatten'], tgt_outputs['flatten'])\n",
    "\n",
    "        joint_loss = loss + coral_loss_weight * loss_coral\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        joint_loss.backward()\n",
    "        # update the parameters according to gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += joint_loss.item()\n",
    "        train_loss += joint_loss.item()\n",
    "\n",
    "        # report every 100 iterations\n",
    "        if idx % 25 == 24:\n",
    "            print(' epoch {} loss: {:.4f}'.format(epoch+1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    train_loss = train_loss/train_steps\n",
    "\n",
    "    print(f'Epoch [{epoch+1}], '\n",
    "          f'Train Loss: {train_loss:.4f}, ')\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaskRCNN requires a backbone with an attached FPN\n",
    "class Resnet34(torch.nn.Module):\n",
    "    def __init__(self, return_nodes, num_classes):\n",
    "        super(Resnet34, self).__init__()\n",
    "        # Get a resnet34 backbone\n",
    "        m = models.resnet34()\n",
    "        train_nodes, eval_nodes = get_graph_node_names(m)\n",
    "        print(eval_nodes)\n",
    "        m.fc = torch.nn.Linear(m.fc.in_features, num_classes)\n",
    "        # Extract 4 main layers\n",
    "        self.body = create_feature_extractor(\n",
    "            m, return_nodes=return_nodes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.add', 'layer1.0.relu_1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.add', 'layer1.1.relu_1', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.relu', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.add', 'layer1.2.relu_1', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.add', 'layer2.1.relu_1', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.relu', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.add', 'layer2.2.relu_1', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.relu', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.add', 'layer2.3.relu_1', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.add', 'layer3.1.relu_1', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.relu', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.add', 'layer3.2.relu_1', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.relu', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.add', 'layer3.3.relu_1', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.relu', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.add', 'layer3.4.relu_1', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.relu', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.add', 'layer3.5.relu_1', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.add', 'layer4.1.relu_1', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.relu', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.add', 'layer4.2.relu_1', 'avgpool', 'flatten', 'fc']\n"
     ]
    }
   ],
   "source": [
    "return_nodes = {\n",
    "    'layer4':'layer4',\n",
    "    'flatten':'flatten',\n",
    "    'fc':'fc'\n",
    "}\n",
    "rn34_model = Resnet34(return_nodes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss: 2.3705, \n",
      "37/391 accuracy 0.09462915360927582\n",
      "Test Error: \n",
      "   Accuracy: 9.46, Avg loss: 2.3724 \n",
      "\n",
      "Epoch: 1 Train_loss: 2.370479871829351 Valid_loss: 2.372389554977417 Valid_acc: 0.09462915360927582\n",
      "Epoch [2], Train Loss: 2.1314, \n",
      "60/391 accuracy 0.15345267951488495\n",
      "Test Error: \n",
      "   Accuracy: 15.35, Avg loss: 2.4444 \n",
      "\n",
      "Epoch: 2 Train_loss: 2.1314078072706857 Valid_loss: 2.4444022178649902 Valid_acc: 0.15345267951488495\n",
      "Epoch [3], Train Loss: 1.9126, \n",
      "44/391 accuracy 0.11253196746110916\n",
      "Test Error: \n",
      "   Accuracy: 11.25, Avg loss: 2.7861 \n",
      "\n",
      "Epoch: 3 Train_loss: 1.9125944872697194 Valid_loss: 2.786140203475952 Valid_acc: 0.11253196746110916\n",
      "Epoch [4], Train Loss: 1.6980, \n",
      "57/391 accuracy 0.1457800567150116\n",
      "Test Error: \n",
      "   Accuracy: 14.58, Avg loss: 2.8406 \n",
      "\n",
      "Epoch: 4 Train_loss: 1.6980008085568745 Valid_loss: 2.8406260013580322 Valid_acc: 0.1457800567150116\n",
      "Epoch [5], Train Loss: 1.4956, \n",
      "52/391 accuracy 0.13299232721328735\n",
      "Test Error: \n",
      "   Accuracy: 13.30, Avg loss: 2.9714 \n",
      "\n",
      "Epoch: 5 Train_loss: 1.4955937663714092 Valid_loss: 2.9714138507843018 Valid_acc: 0.13299232721328735\n",
      "Epoch [6], Train Loss: 1.4511, \n",
      "60/391 accuracy 0.15345267951488495\n",
      "Test Error: \n",
      "   Accuracy: 15.35, Avg loss: 2.7769 \n",
      "\n",
      "Epoch: 6 Train_loss: 1.4511421124140422 Valid_loss: 2.776932954788208 Valid_acc: 0.15345267951488495\n",
      "Epoch [7], Train Loss: 1.2839, \n",
      "54/391 accuracy 0.13810741901397705\n",
      "Test Error: \n",
      "   Accuracy: 13.81, Avg loss: 3.4832 \n",
      "\n",
      "Epoch: 7 Train_loss: 1.2838774273792903 Valid_loss: 3.4831626415252686 Valid_acc: 0.13810741901397705\n",
      "Epoch [8], Train Loss: 1.2465, \n",
      "60/391 accuracy 0.15345267951488495\n",
      "Test Error: \n",
      "   Accuracy: 15.35, Avg loss: 3.7912 \n",
      "\n",
      "Epoch: 8 Train_loss: 1.2465418875217438 Valid_loss: 3.7912063598632812 Valid_acc: 0.15345267951488495\n",
      "Epoch [9], Train Loss: 1.1293, \n",
      "44/391 accuracy 0.11253196746110916\n",
      "Test Error: \n",
      "   Accuracy: 11.25, Avg loss: 2.8741 \n",
      "\n",
      "Epoch: 9 Train_loss: 1.129269964993 Valid_loss: 2.8740832805633545 Valid_acc: 0.11253196746110916\n",
      "Epoch [10], Train Loss: 1.0817, \n",
      "60/391 accuracy 0.15345267951488495\n",
      "Test Error: \n",
      "   Accuracy: 15.35, Avg loss: 3.0671 \n",
      "\n",
      "Epoch: 10 Train_loss: 1.081653726597627 Valid_loss: 3.0670785903930664 Valid_acc: 0.15345267951488495\n",
      "Epoch [11], Train Loss: 1.0825, \n",
      "65/391 accuracy 0.1662404090166092\n",
      "Test Error: \n",
      "   Accuracy: 16.62, Avg loss: 3.4160 \n",
      "\n",
      "Epoch: 11 Train_loss: 1.0825376709302266 Valid_loss: 3.4159998893737793 Valid_acc: 0.1662404090166092\n",
      "Epoch [12], Train Loss: 0.9687, \n",
      "66/391 accuracy 0.16879795491695404\n",
      "Test Error: \n",
      "   Accuracy: 16.88, Avg loss: 3.2520 \n",
      "\n",
      "Epoch: 12 Train_loss: 0.9686589936415354 Valid_loss: 3.2520055770874023 Valid_acc: 0.16879795491695404\n",
      "Epoch [13], Train Loss: 1.0194, \n",
      "74/391 accuracy 0.18925830721855164\n",
      "Test Error: \n",
      "   Accuracy: 18.93, Avg loss: 2.9550 \n",
      "\n",
      "Epoch: 13 Train_loss: 1.0194495568672817 Valid_loss: 2.9550280570983887 Valid_acc: 0.18925830721855164\n",
      "Epoch [14], Train Loss: 0.9520, \n",
      "79/391 accuracy 0.20204603672027588\n",
      "Test Error: \n",
      "   Accuracy: 20.20, Avg loss: 3.3089 \n",
      "\n",
      "Epoch: 14 Train_loss: 0.9519628485043844 Valid_loss: 3.3088693618774414 Valid_acc: 0.20204603672027588\n",
      "Epoch [15], Train Loss: 0.9177, \n",
      "64/391 accuracy 0.16368286311626434\n",
      "Test Error: \n",
      "   Accuracy: 16.37, Avg loss: 3.8103 \n",
      "\n",
      "Epoch: 15 Train_loss: 0.9177270084619522 Valid_loss: 3.810263156890869 Valid_acc: 0.16368286311626434\n",
      "Epoch [16], Train Loss: 0.9330, \n",
      "82/391 accuracy 0.20971867442131042\n",
      "Test Error: \n",
      "   Accuracy: 20.97, Avg loss: 3.0009 \n",
      "\n",
      "Epoch: 16 Train_loss: 0.9330460429191589 Valid_loss: 3.0008647441864014 Valid_acc: 0.20971867442131042\n",
      "Epoch [17], Train Loss: 0.8621, \n",
      "72/391 accuracy 0.18414321541786194\n",
      "Test Error: \n",
      "   Accuracy: 18.41, Avg loss: 3.2358 \n",
      "\n",
      "Epoch: 17 Train_loss: 0.8621335377295812 Valid_loss: 3.235783338546753 Valid_acc: 0.18414321541786194\n",
      "Epoch [18], Train Loss: 0.8722, \n",
      "72/391 accuracy 0.18414321541786194\n",
      "Test Error: \n",
      "   Accuracy: 18.41, Avg loss: 3.1093 \n",
      "\n",
      "Epoch: 18 Train_loss: 0.8721587037046751 Valid_loss: 3.1092991828918457 Valid_acc: 0.18414321541786194\n",
      "Epoch [19], Train Loss: 0.8094, \n",
      "73/391 accuracy 0.1867007613182068\n",
      "Test Error: \n",
      "   Accuracy: 18.67, Avg loss: 3.2976 \n",
      "\n",
      "Epoch: 19 Train_loss: 0.8093849966923395 Valid_loss: 3.2976481914520264 Valid_acc: 0.1867007613182068\n",
      "Epoch [20], Train Loss: 0.7543, \n",
      "72/391 accuracy 0.18414321541786194\n",
      "Test Error: \n",
      "   Accuracy: 18.41, Avg loss: 3.3662 \n",
      "\n",
      "Epoch: 20 Train_loss: 0.7542907819151878 Valid_loss: 3.366187334060669 Valid_acc: 0.18414321541786194\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "## Optimizer construction using SGD\n",
    "params = [p for p in rn34_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=5e-4,\n",
    "    momentum=0.9\n",
    ")\n",
    "rn34_model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# ******************* TensorBoard *******************\n",
    "writer = SummaryWriter(comment=\"ass2\")\n",
    "\n",
    "# ******************* Optimization *******************\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    # set the module in training mode.\n",
    "    rn34_model.train()\n",
    "    train_loss = train_coral(dl_train_real, dl_train_sketch, rn34_model, loss_fn, optimizer, epoch, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "\n",
    "    # save model weights\n",
    "    save_path = 'ckpt_{:04d}_22.pth'.format(epoch+1)\n",
    "    torch.save(rn34_model.state_dict(), save_path)\n",
    "\n",
    "    # validation loop\n",
    "    # set the module in evaluation mode.\n",
    "    rn34_model.eval()\n",
    "    valid_loss, valid_accuracy = test(dl_valid_sketch, rn34_model, loss_fn, device)\n",
    "    # save to tensorboard\n",
    "    writer.add_scalar('valid_loss', valid_loss, epoch)\n",
    "    writer.add_scalar('valid_accuracy', valid_accuracy, epoch)\n",
    "\n",
    "    if valid_accuracy > best_accuracy:    # save the model with best validation accuracy\n",
    "        save_path = 'ckpt_best_22.pth'\n",
    "        torch.save(rn34_model.state_dict(), save_path)\n",
    "        best_accuracy = valid_accuracy\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}', f'Train_loss: {train_loss}', f'Valid_loss: {valid_loss}', f'Valid_acc: {valid_accuracy}')\n",
    "\n",
    "writer.close()\n",
    "print(\"Finished Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
